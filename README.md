# ğŸ“ˆ Stock Market Data Pipeline & Analytics
îˆƒA complete data engineering and analytics project that automates the extraction, transformation, and loading (ELT) of stock market data, followed by insightful reporting and visualizationîˆ„îˆ†

---

## ğŸš€ Project Overview
îˆƒThis project demonstrates an end-to-end data pipeline for stock market analysis, encompassin:îˆ„îˆ†

- **Data Extraction** îˆƒRetrieving stock prices, company fundamentals, news sentiment, and economic indicator.îˆ„
- **Data Loading** îˆƒStoring raw data into Snowflake data warehous.îˆ„
- **Data Transformation** îˆƒUtilizing dbt for data modeling and transformatio.îˆ„
- **Orchestration** îˆƒManaging workflows with Dagster, including scheduling and dependency managemen.îˆ„
- **Reporting** îˆƒGenerating dashboards and reports for data visualizatio.îˆ„îˆ†

---

## ğŸ§± Project Structur

îˆƒ
``bash
â”œâ”€â”€ EL/                          # Data extraction scripts
â”œâ”€â”€ Reports/                     # Generated reports and dashboards
â”œâ”€â”€ SnowflakeScripts/            # SQL scripts for Snowflake setup
â”œâ”€â”€ T/finance_analytics/         # dbt project for data transformation
â”œâ”€â”€ orchestration/               # Dagster pipelines and configurations
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
``
îˆ„îˆ†

---

## âš™ï¸ Setup & Installation

1. **Clone the Repository**

   ```bash
   git clone https://github.com/Sidarth-Roy/Complete-Stock-Market-Analysis-DE-DA.git
   cd Complete-Stock-Market-Analysis-DE-DA
   ``
îˆ„îˆ†

2. **Create Virtual Environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ``
îˆ„îˆ†

3. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ``
îˆ„îˆ†

4. **Configure Environment Variables**

   Set up necessary environment variables for Snowflake credentials and API keys.

5. **Initialize Snowflake**

   Run the SQL scripts in `SnowflakeScripts/` to set up the database schema.

---

## ğŸ› ï¸ Usage

1. **Run Data Extraction**

   Execute the scripts in the `EL/` directory to extract data from various sources.

2. **Load Data into Snowflake**

   Use the provided scripts to load the extracted data into the Snowflake data warehouse.

3. **Transform Data with dbt**

   Navigate to the `T/finance_analytics/` directory and run:

   ```bash
   dbt run
   ``
îˆ„îˆ†

4. **Orchestrate with Dagster**

   Use Dagster to schedule and manage the workflows defined in the `orchestration/` directory.

5. **Generate Reports**

   Access the generated reports and dashboards in the `Reports/` directory.

---

## ğŸ“Š Sample Dashbord

îˆƒ![Sample Dashboard](Reports/sample_dashboardpng)îˆ„îˆ†

---

## ğŸ“… Scheduling & Orchestraion

îˆƒThe project utilizes Dagster for orchestration, with the following scheules:îˆ„îˆ†

- **Data Ingestion Pipelie**: îˆƒRuns daily at midnight to extract and loaddata.îˆ„
- **Data Transformation Pipelie**: îˆƒRuns daily at 2 AM to transform data usin db.îˆ„îˆ†

îˆƒThese schedules ensure timely data processing and availability for repoting.îˆ„îˆ†

---

## ğŸ¤ Contribting

îˆƒContributions are welcome! Please follow thesesteps:îˆ†

1. îˆƒFork the repoitor.îˆ„
2. îˆƒCreate a new branch: `git checkout -b featurename.îˆ„
3. îˆƒMake your cange.îˆ„
4. îˆƒCommit your changes: `git commit -m 'Add new feaure'.îˆ„
5. îˆƒPush to the branch: `git push origin featurename.îˆ„
6. îˆƒOpen a pull rquest.îˆ„îˆ†

---

## ğŸ“„ Lcense

îˆƒThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for etails.îˆ„îˆ†

---

## ğŸ“¬ ontact

îˆƒFor questions or suggestions, feel free to rach out:îˆ„îˆ†

- **GitHub**: [Sidarth-Roy](https://github.com/Sidarth-Roy)
- **mail**: îˆƒ[your.email@example.com](mailto:your.email@exaple.com)îˆ„îˆ†

---

Feel free to customize this `README.md` further to suit your project's specific needs. 
